# Projeto: Web Scraping com Crawl4AI

Este projeto utiliza a biblioteca [Crawl4AI](https://github.com/unclecode/crawl4ai) para realizar scraping de sites de forma ass√≠ncrona. O c√≥digo busca informa√ß√µes da p√°gina de not√≠cias da NBC e retorna o conte√∫do formatado em Markdown.

## üìå Tecnologias Utilizadas
- **Python 3.8+**
- **Crawl4AI** (para scraping)
- **Asyncio** (para execu√ß√£o ass√≠ncrona)

## üöÄ Instala√ß√£o e Configura√ß√£o
Para rodar este projeto localmente, siga os passos abaixo:

### 1Ô∏è‚É£ **Clone o reposit√≥rio**
```sh
 git clone https://github.com/felipebossolani/crawl4ai-first-crawler.git
 cd crawl4ai-first-crawler
```

### 2Ô∏è‚É£ **Crie um ambiente virtual (opcional, mas recomendado)**
```sh
python3 -m venv venv
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate    # Windows
```

### 3Ô∏è‚É£ **Instale as depend√™ncias**
```sh
pip install crawl4ai
```

## üìù Como Usar
Execute o script para rodar o crawler:

```sh
python main.py
```

### üìú C√≥digo Principal (`main.py`)
```python
import asyncio
from crawl4ai import *

async def main():
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://www.nbcnews.com/business",
        )
        print(result.markdown)

if __name__ == "__main__":
    asyncio.run(main())
```

## ‚ÑπÔ∏è Sobre a Biblioteca Crawl4AI
[Crawl4AI](https://github.com/unclecode/crawl4ai) √© uma biblioteca Python para web scraping ass√≠ncrono, ideal para extra√ß√£o de dados de p√°ginas da web de maneira eficiente. Suporta integra√ß√£o com intelig√™ncia artificial para extra√ß√£o avan√ßada de informa√ß√µes.

## üìå Pr√≥ximos Passos
- Melhorar o tratamento dos dados extra√≠dos
- Adicionar suporte a m√∫ltiplas URLs
- Explorar funcionalidades avan√ßadas do Crawl4AI

---
Criado por [Felipe Bossolani](https://github.com/felipebossolani).

